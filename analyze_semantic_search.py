"""
Script de demonstra√ß√£o da busca sem√¢ntica
Conecta diretamente ao banco e executa busca sem depender do servidor web
"""
import os
os.environ['DATABASE_URL'] = "postgresql://postgres:rx1800@localhost:5433/hub_aura_db"

import numpy as np
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from sentence_transformers import SentenceTransformer
import time
from datetime import datetime

# Configura√ß√£o do banco
DB_URL = "postgresql://postgres:rx1800@localhost:5433/hub_aura_db"
engine = create_engine(DB_URL)
Session = sessionmaker(bind=engine)

def analyze_semantic_search():
    """Executa busca sem√¢ntica diretamente no banco"""
    
    query_text = "quais os melhores parceiros para uma capacita√ß√£o em intelig√™ncia"
    
    print("=" * 100)
    print("RELAT√ìRIO DE AN√ÅLISE DE BUSCA SEM√ÇNTICA - HUB AURA TCE")
    print("=" * 100)
    print(f"\nüìÖ Data/Hora: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print(f"üîç Query: '{query_text}'")
    print(f"üíæ Banco: PostgreSQL (localhost:5433/hub_aura_db)")
    print(f"ü§ñ Modelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    try:
        # Carregar modelo
        print("\n" + "-" * 100)
        print("‚è≥ Carregando modelo de IA...")
        model_start = time.time()
        model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
        model_time = time.time() - model_start
        print(f"‚úÖ Modelo carregado em {model_time:.2f}s")
        
        # Gerar embedding da query
        print(f"\n‚è≥ Gerando embedding da query...")
        embed_start = time.time()
        query_vector = model.encode(query_text).tolist()
        embed_time = time.time() - embed_start
        print(f"‚úÖ Embedding gerado em {embed_time:.3f}s ({len(query_vector)} dimens√µes)")
        
        # Calcular norma
        q_norm = float(np.sqrt(np.sum(np.square(np.array(query_vector, dtype=np.float64)))))
        
        # Executar busca no banco
        print(f"\n‚è≥ Executando busca sem√¢ntica no banco de dados...")
        db_start = time.time()
        
        session = Session()
        
        sql = text("""
            WITH q AS (
                SELECT CAST(:query_vector AS float8[]) AS v, CAST(:q_norm AS float8) AS qn
            ),
            deduplicated_vectors AS (
                SELECT DISTINCT ON (parceria_id) 
                    parceria_id, 
                    COALESCE(objeto_vetor_v3, objeto_vetor_v2) as vetor
                FROM documento_vetores
                WHERE COALESCE(objeto_vetor_v3, objeto_vetor_v2) IS NOT NULL
                ORDER BY parceria_id
            ),
            agg AS (
                SELECT 
                    dv.parceria_id,
                    SUM(dv_elt.dv_v * q_elt.q_v) AS dot,
                    sqrt(SUM(dv_elt.dv_v * dv_elt.dv_v)) AS dn
                FROM deduplicated_vectors dv
                JOIN q ON TRUE
                JOIN LATERAL unnest(dv.vetor) WITH ORDINALITY AS dv_elt(dv_v, idx) ON TRUE
                JOIN LATERAL unnest((SELECT v FROM q)) WITH ORDINALITY AS q_elt(q_v, idx2) ON idx = idx2
                GROUP BY dv.parceria_id
            )
            SELECT 
                p.*,
                (dot / NULLIF(dn * (SELECT qn FROM q), 0)) AS similarity_score
            FROM agg a
            JOIN instrumentos_parceria p ON p.id = a.parceria_id
            ORDER BY similarity_score DESC NULLS LAST
            LIMIT 10
        """)
        
        result = session.execute(sql, {
            "query_vector": query_vector,
            "q_norm": q_norm
        })
        
        rows = result.mappings().all()
        db_time = time.time() - db_start
        
        print(f"‚úÖ Busca conclu√≠da em {db_time:.3f}s")
        
        # Tempo total
        total_time = model_time + embed_time + db_time
        
        # An√°lise de performance
        print("\n" + "=" * 100)
        print("üìä AN√ÅLISE DE PERFORMANCE DA IA")
        print("=" * 100)
        
        print(f"\n‚è±Ô∏è  Tempos de Execu√ß√£o:")
        print(f"   ‚Ä¢ Carregamento do Modelo: {model_time:.2f}s")
        print(f"   ‚Ä¢ Gera√ß√£o de Embedding: {embed_time:.3f}s ({embed_time*1000:.0f}ms)")
        print(f"   ‚Ä¢ Busca no Banco de Dados: {db_time:.3f}s ({db_time*1000:.0f}ms)")
        print(f"   ‚Ä¢ TEMPO TOTAL: {total_time:.2f}s")
        
        # Classifica√ß√£o de performance
        if embed_time + db_time < 0.5:
            perf = "EXCELENTE ‚ö°"
        elif embed_time + db_time < 1.0:
            perf = "MUITO BOA üü¢"
        elif embed_time + db_time < 2.0:
            perf = "BOA üü°"
        else:
            perf = "ACEIT√ÅVEL üü†"
        
        print(f"\nüìà Performance (excluindo carregamento inicial): {perf}")
        print(f"   ‚Ä¢ Lat√™ncia de busca: {(embed_time + db_time)*1000:.0f}ms")
        
        print(f"\nüîß Especifica√ß√µes T√©cnicas:")
        print(f"   ‚Ä¢ Device: CPU")
        print(f"   ‚Ä¢ Dimens√µes do vetor: {len(query_vector)}")
        print(f"   ‚Ä¢ M√©trica de similaridade: Cosseno")
        print(f"   ‚Ä¢ Banco de dados: PostgreSQL 15")
        print(f"   ‚Ä¢ Framework: sentence-transformers + SQLAlchemy")
        
        # Resultados
        print("\n" + "=" * 100)
        print(f"üéØ AN√ÅLISE DETALHADA DOS {len(rows)} RESULTADOS ENCONTRADOS")
        print("=" * 100)
        
        if rows:
            scores = []
            parceiros = {}
            
            for idx, row in enumerate(rows, 1):
                item = dict(row)
                score = float(item.get('similarity_score', 0))
                scores.append(score)
                
                # Contar parceiros
                parceiro = item.get('nome_parceiro', 'Desconhecido')
                parceiros[parceiro] = parceiros.get(parceiro, 0) + 1
                
                print(f"\n{'‚îÄ' * 100}")
                print(f"üìã RESULTADO #{idx}")
                print(f"{'‚îÄ' * 100}")
                
                # Dados principais
                print(f"\nüÜî Termo N¬∫: {item.get('numero_do_termo', 'N/A')}/{item.get('ano_do_termo', 'N/A')}")
                print(f"üè¢ Parceiro: {parceiro}")
                print(f"üìÖ Data de Assinatura: {item.get('data_assinatura', 'N/A')}")
                print(f"‚è∞ Vig√™ncia: {item.get('data_inicio_vigencia', 'N/A')} ‚Üí {item.get('data_fim_vigencia', 'N/A')}")
                
                if item.get('tipo_instrumento'):
                    print(f"üìÑ Tipo: {item.get('tipo_instrumento')}")
                if item.get('unidade_gestora'):
                    print(f"üèõÔ∏è  Unidade Gestora: {item.get('unidade_gestora')}")
                
                # Score de similaridade
                print(f"\nüéØ Score de Similaridade: {score:.4f} ({score*100:.2f}%)")
                
                # Classifica√ß√£o de relev√¢ncia
                if score >= 0.7:
                    relevancia = "MUITO ALTA"
                    emoji = "üü¢"
                elif score >= 0.5:
                    relevancia = "ALTA"
                    emoji = "üü°"
                elif score >= 0.3:
                    relevancia = "M√âDIA"
                    emoji = "üü†"
                else:
                    relevancia = "BAIXA"
                    emoji = "üî¥"
                
                print(f"   {emoji} Relev√¢ncia: {relevancia}")
                
                # Objeto
                objeto = item.get('objeto', '')
                if objeto:
                    print(f"\nüí° Objeto do Termo:")
                    if len(objeto) > 250:
                        print(f"   {objeto[:250]}...")
                    else:
                        print(f"   {objeto}")
                
                # An√°lise de keywords
                print(f"\nüîç An√°lise de Relev√¢ncia para a Query:")
                objeto_lower = objeto.lower() if objeto else ''
                parceiro_lower = parceiro.lower()
                
                keywords_found = []
                
                # Busca por termos relacionados √† query
                if any(term in objeto_lower or term in parceiro_lower for term in ['capacita√ß√£o', 'capacitacao']):
                    keywords_found.append("‚úì Menciona 'capacita√ß√£o'")
                
                if any(term in objeto_lower or term in parceiro_lower for term in ['intelig√™ncia', 'inteligencia', 'artificial', 'ia']):
                    keywords_found.append("‚úì Relacionado a 'intelig√™ncia/IA'")
                
                if any(term in objeto_lower for term in ['ensino', 'educa√ß√£o', 'educacao', 'treinamento', 'forma√ß√£o', 'formacao', 'curso']):
                    keywords_found.append("‚úì √Årea de ensino/educa√ß√£o/treinamento")
                
                if any(term in objeto_lower for term in ['tecnologia', 'inova√ß√£o', 'inovacao', 'digital', 'dados']):
                    keywords_found.append("‚úì Envolve tecnologia/inova√ß√£o")
                
                if any(term in objeto_lower for term in ['pesquisa', 'desenvolvimento', 'ci√™ncia', 'ciencia', 'cient√≠fico', 'cientifico']):
                    keywords_found.append("‚úì Atividades de pesquisa/desenvolvimento")
                
                if keywords_found:
                    for kw in keywords_found:
                        print(f"   {kw}")
                else:
                    print(f"   ‚Ä¢ Relev√¢ncia baseada em similaridade sem√¢ntica vetorial")
                    print(f"   ‚Ä¢ O modelo identificou correla√ß√£o contextual com a query")
            
            # Estat√≠sticas agregadas
            print(f"\n{'=' * 100}")
            print("üìä ESTAT√çSTICAS AGREGADAS")
            print(f"{'=' * 100}")
            
            print(f"\nüìà Scores de Similaridade:")
            print(f"   ‚Ä¢ M√°ximo: {max(scores):.4f} ({max(scores)*100:.2f}%)")
            print(f"   ‚Ä¢ M√≠nimo: {min(scores):.4f} ({min(scores)*100:.2f}%)")
            print(f"   ‚Ä¢ M√©dia: {sum(scores)/len(scores):.4f} ({(sum(scores)/len(scores))*100:.2f}%)")
            print(f"   ‚Ä¢ Mediana: {sorted(scores)[len(scores)//2]:.4f}")
            
            # Distribui√ß√£o
            muito_alta = sum(1 for s in scores if s >= 0.7)
            alta = sum(1 for s in scores if 0.5 <= s < 0.7)
            media = sum(1 for s in scores if 0.3 <= s < 0.5)
            baixa = sum(1 for s in scores if s < 0.3)
            
            print(f"\nüìä Distribui√ß√£o de Relev√¢ncia:")
            print(f"   üü¢ Muito Alta (‚â•70%): {muito_alta} resultado(s) - {muito_alta/len(scores)*100:.1f}%")
            print(f"   üü° Alta (50-69%): {alta} resultado(s) - {alta/len(scores)*100:.1f}%")
            print(f"   üü† M√©dia (30-49%): {media} resultado(s) - {media/len(scores)*100:.1f}%")
            print(f"   üî¥ Baixa (<30%): {baixa} resultado(s) - {baixa/len(scores)*100:.1f}%")
            
            # Parceiros
            print(f"\nü§ù Parceiros Identificados ({len(parceiros)}):")
            for parceiro, count in sorted(parceiros.items(), key=lambda x: x[1], reverse=True):
                print(f"   ‚Ä¢ {parceiro}: {count} termo(s)")
            
            # Conclus√µes e recomenda√ß√µes
            print(f"\n{'=' * 100}")
            print("üí° CONCLUS√ïES E RECOMENDA√á√ïES")
            print(f"{'=' * 100}")
            
            print(f"\n‚úÖ Pontos Fortes:")
            print(f"   ‚Ä¢ Performance de busca r√°pida ({(embed_time + db_time)*1000:.0f}ms)")
            print(f"   ‚Ä¢ Modelo multil√≠ngue otimizado para portugu√™s")
            print(f"   ‚Ä¢ Busca vetorial escal√°vel com PostgreSQL")
            print(f"   ‚Ä¢ Retornou {len(rows)} resultados relevantes")
            
            if max(scores) >= 0.5:
                print(f"   ‚Ä¢ Resultados com alta similaridade encontrados")
            
            if embed_time + db_time > 1.0:
                print(f"\n‚ö†Ô∏è  Pontos de Aten√ß√£o:")
                print(f"   ‚Ä¢ Lat√™ncia pode ser melhorada com GPU")
                print(f"   ‚Ä¢ Considerar cache de embeddings para queries frequentes")
            
            if max(scores) < 0.5:
                print(f"\nüí° Sugest√µes de Melhoria:")
                print(f"   ‚Ä¢ Scores baixos - considerar fine-tuning do modelo")
                print(f"   ‚Ä¢ Enriquecer base de dados com mais documentos")
                print(f"   ‚Ä¢ Avaliar uso de modelo maior (mais par√¢metros)")
            else:
                print(f"\nüí° Sugest√µes de Melhoria:")
                print(f"   ‚Ä¢ Implementar cache de embeddings para melhor performance")
                print(f"   ‚Ä¢ Considerar indexa√ß√£o HNSW para bases maiores")
                print(f"   ‚Ä¢ Avaliar uso de GPU para reduzir lat√™ncia")
            
            # Compara√ß√£o com busca tradicional
            print(f"\nüîÑ Vantagens sobre Busca Tradicional (keyword-based):")
            print(f"   ‚Ä¢ Entende sin√¥nimos e contexto sem√¢ntico")
            print(f"   ‚Ä¢ N√£o depende de correspond√™ncia exata de palavras")
            print(f"   ‚Ä¢ Captura rela√ß√µes conceituais ('capacita√ß√£o' ‚Üî 'treinamento', 'intelig√™ncia' ‚Üî 'IA')")
            print(f"   ‚Ä¢ Ranqueamento por similaridade vetorial (mais preciso)")
            
        else:
            print("\n‚ö†Ô∏è  Nenhum resultado encontrado.")
            print("\nPoss√≠veis causas:")
            print("   ‚Ä¢ Tabela documento_vetores vazia")
            print("   ‚Ä¢ Embeddings n√£o gerados para os documentos")
            print("   ‚Ä¢ Problema na query SQL")
        
        session.close()
        
    except Exception as e:
        print(f"\n‚ùå ERRO: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'=' * 100}")
    print("‚úì RELAT√ìRIO CONCLU√çDO")
    print(f"{'=' * 100}\n")

if __name__ == "__main__":
    print("\nüöÄ Iniciando an√°lise de busca sem√¢ntica...\n")
    analyze_semantic_search()
